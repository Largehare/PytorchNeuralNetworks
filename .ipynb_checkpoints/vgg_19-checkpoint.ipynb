{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用VGG19对CIFAR10数据集进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19起源与介绍\n",
    "VGGNet是牛津大学计算机视觉组（Visual Geometry Group）和Google DeepMind公司的研究员一起研发的卷积神经网络。VGGNet探索了卷积神经网络的深度与其性能之间的关系，通过反复的使用$3\\times3$的小型卷积核和$2\\times2$的最大池化层，VGGNet成功地构筑了16～19层深的卷积神经网络。\n",
    "如图所示，即为VGG19的网络结构：\n",
    "![png](https://raw.githubusercontent.com/shiyadong123/Myimage/master/20170816092916647.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16与VGG19的直观对比\n",
    "![png](https://github.com/shiyadong123/Myimage/blob/master/20190217165325787.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预准备\n",
    "在搭建VGG19网络结构之前，首先做预准备，包括：\n",
    "+ 1.导入必要的库\n",
    "+ 2.CIFAR10数据集的预处理\n",
    "+ 3.定义训练模型用的辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.导入必要的库\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as trans\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "BATCH_SIZE = 100\n",
    "nepochs = 50\n",
    "LR = 0.001\n",
    "\n",
    "# 定义损失函数为交叉熵损失 loss_func\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 可以在GPU或者CPU上运行\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.CIFAR10数据集的预处理\n",
    "\n",
    "# CIFAR10的输入图片各channel的均值 mean 和标准差 std \n",
    "mean = [x/255 for x in [125.3, 23.0, 113.9]] \n",
    "std = [x/255 for x in [63.0, 62.1, 66.7]]\n",
    "n_train_samples = 50000\n",
    "# 全局取消证书验证\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# 如果是多进程需要加一个main函数，否则会报错\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # 数据增强-->训练集\n",
    "    train_set = dsets.CIFAR10(root='CIFAR10/',  # 数据集保存路径\n",
    "                              train=True,\n",
    "                              download=False,   # 如果未下载，改为True；如果已经下载好，改为False\n",
    "                              transform=trans.Compose([\n",
    "                                 trans.RandomHorizontalFlip(),\n",
    "                                 trans.RandomCrop(32, padding=4),\n",
    "                                 trans.ToTensor(),\n",
    "                                 trans.Normalize(mean, std)\n",
    "                             ]))\n",
    "    train_dl = DataLoader(train_set,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=6)        # 多进程\n",
    "    \n",
    "    # train_set.train_data = train_set.train_data[0:n_train_samples]\n",
    "    # train_set.train_labels = train_set.train_labels[0:n_train_samples]\n",
    "    \n",
    "    # 测试集\n",
    "    test_set = dsets.CIFAR10(root='CIFAR10/',   # 数据集保存路径\n",
    "                             train=False,\n",
    "                             download=False,    # 如果未下载，改为True；如果已经下载好，改为False\n",
    "                             transform=trans.Compose([\n",
    "                                trans.ToTensor(),\n",
    "                                trans.Normalize(mean, std)\n",
    "                            ]))\n",
    "\n",
    "    test_dl = DataLoader(test_set,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=6)         # 多进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.定义训练的辅助函数，其中包括误差 error 与正确率 accuracy\n",
    "def eval(model, loss_func, dataloader):\n",
    "\n",
    "    model.eval()\n",
    "    loss, accuracy = 0, 0\n",
    "    \n",
    "    # torch.no_grad显示地告诉pytorch，前向传播的时候不需要存储计算图\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            logits = model(batch_x)\n",
    "            error = loss_func(logits, batch_y)\n",
    "            loss += error.item()\n",
    "\n",
    "            probs, pred_y = logits.data.max(dim=1)\n",
    "            accuracy += (pred_y==batch_y.data).float().sum()/batch_y.size(0)\n",
    "\n",
    "    loss /= len(dataloader)\n",
    "    accuracy = accuracy*100.0/len(dataloader)\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def train_epoch(model, loss_func, optimizer, dataloader):\n",
    "\n",
    "    model.train()\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_x)\n",
    "        error = loss_func(logits, batch_y)\n",
    "        error.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19网络结构\n",
    "![png](https://github.com/shiyadong123/Myimage/blob/master/68747470733a2f2f6c6968616e2e6d652f6173736574732f696d616765732f7667672d6865726f2d636f7665722e6a7067.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据上图的VGG19网络结构，开始正式搭建VGG19模型，为了方便起见，先定义卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积层，在VGGNet中，均使用3x3的卷积核\n",
    "def conv3x3(in_features, out_features): \n",
    "    return nn.Conv2d(in_features, out_features, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建VGG19，除了卷积层外，还包括2个全连接层（fc_1、fc_2），1个softmax层\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 1.con1_1\n",
    "            conv3x3(3, 64),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # 2.con1_2\n",
    "            conv3x3(64, 64),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # 3.con2_1\n",
    "            conv3x3(64, 128),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # 4.con2_2\n",
    "            conv3x3(128, 128),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # 5.con3_1\n",
    "            conv3x3(128, 256),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # 6.con3_2\n",
    "            conv3x3(256, 256),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # 7.con3_3\n",
    "            conv3x3(256, 256),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # 8.con3_4\n",
    "            conv3x3(256, 256),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # 9.con4_1\n",
    "            conv3x3(256, 512),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # 10.con4_2\n",
    "            conv3x3(512, 512),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # 11.con4_3\n",
    "            conv3x3(512, 512),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # 12.con4_4\n",
    "            conv3x3(512, 512),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # 13.con5_1\n",
    "            conv3x3(512, 512),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # 14.con5_2\n",
    "            conv3x3(512, 512),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # 15.con5_3\n",
    "            conv3x3(512, 512),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # 16.con5_4\n",
    "            conv3x3(512, 512),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            # 17.fc_1\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            # 18.fc_2\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            # 19.softmax\n",
    "            nn.Linear(4096, 10),  # 最后通过softmax层，输出10个类别\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义好VGG19网络之后，开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG().to(device)\n",
    "# 可以通过打印vgg19观察具体的网络结构\n",
    "# print(vgg19) \n",
    "\n",
    "# 使用Adam进行优化处理\n",
    "optimizer = torch.optim.Adam(vgg19.parameters(), lr=LR)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[40], gamma=0.1)\n",
    "learn_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练VGG19……\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f7a8771e04d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# 训练开始时间\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msince\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# 每训练5轮输出一次结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-f3872a804342>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, loss_func, optimizer, dataloader)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\App\\Anaconda\\envs\\py38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\App\\Anaconda\\envs\\py38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('开始训练VGG19……')\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    # 训练开始时间\n",
    "    since = time.time()\n",
    "    train_epoch(vgg19, loss_func, optimizer, train_dl)\n",
    "    \n",
    "    # 每训练5轮输出一次结果\n",
    "    if (epoch)%1 == 0:\n",
    "        tr_loss, tr_acc = eval(vgg19, loss_func, train_dl)\n",
    "        te_loss, te_acc = eval(vgg19, loss_func, test_dl)\n",
    "        learn_history.append((tr_loss, tr_acc, te_loss, te_acc))\n",
    "        # 完成一批次训练的结束时间\n",
    "        now = time.time()\n",
    "        print('[%3d/%d, %.0f seconds]|\\t 训练误差: %.1e, 训练正确率: %.2f\\t |\\t 测试误差: %.1e, 测试正确率: %.2f'%(\n",
    "            epoch+1, nepochs, now-since, tr_loss, tr_acc, te_loss, te_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据输出的结果，我们可以很明显的看出，在训练轮次增加后，正确率有了明显的提高，训练完50轮后，测试集的正确率达到89.16%，如果我们进一步增加训练轮次，正确率应该还会更高。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
